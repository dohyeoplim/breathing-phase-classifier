# ğŸ« A Deep Learning Approach to Respiratory Phase Detection from Audio Spectrograms

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/dohyeoplim/a83fa674e537473f1adb66960db0a32c/kaggle_2_v3.ipynb)

Developed by:

- **Dohyeop Lim** â€” Dept. of Artificial Intelligence, Seoul National University of Science and Technology  
- **Songwon Won** â€” Dept. of Artificial Intelligence, Seoul National University of Science and Technology
  
<br/>

## ğŸš€ Quick Start


**Project Structure:**
```plaintext
â”œâ”€â”€ main.py              # Main entry point for training or precomputing
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ augmentation.py  # CutMix and Mixup
â”‚   â”œâ”€â”€ dataset.py       # Dataset Class from the precomputed features
â”‚   â”œâ”€â”€ model.py         # Model architectures
â”‚   â”œâ”€â”€ train.py         # Train logics
â”‚   â”œâ”€â”€ precompute/      # Feature extraction pipeline: spectrograms, scalars, and preprocessing utilities
â”‚   â””â”€â”€ scripts/         # Training and evaluation routines
â””â”€â”€ README.md
```

**Train and Predict:**
```bash
python main.py
```

**Precompute Features Only:**
```bash
python main.py --precompute
```

<br/>

## ğŸ“Š Dataset Overview

### ğŸ“ Provided Files

- **`train/`**: Labeled `.wav` files of single breathing phases (inhale/exhale).
- **`test/`**: Unlabeled `.wav` files for evaluation.
- **`train.csv`**: Metadata linking `train/` files to ground-truth labels.
- **`test.csv`**: IDs of `test/` files to be predicted.

### ğŸ“ Column Descriptions

#### `train.csv`

| Column     | Type   | Description                                  |
|------------|--------|----------------------------------------------|
| file_name  | string | ID matching a `.wav` file in `train/`        |
| label      | string | Breathing phase: `I` = Inhale, `E` = Exhale |

#### `test.csv`

| Column | Type   | Description                            |
|--------|--------|----------------------------------------|
| ID     | string | ID matching a `.wav` file in `test/`   |
<br />

## ğŸ§  Model Overview

### ğŸ“¦ CNN8
A compact 8-layer convolutional neural network.

- **Input**:  
  - Spectrogram input: `shape = [B, 9, H, W]`  
  - Scalar input: 39-dimensional waveform-derived vector

- **Spectrogram Branch**:
  - 4 convolutional blocks:
    - Conv2D â†’ ReLU â†’ BatchNorm
    - MaxPool2D and Dropout2D applied after 2nd and 4th blocks
  - Final: `AdaptiveAvgPool2d((1, 1))` to produce global feature map

- **Scalar Branch**:
  - Linear(39 â†’ 64) â†’ ReLU â†’ BatchNorm â†’ Dropout  
  - Linear(64 â†’ 64) â†’ ReLU â†’ BatchNorm

- **Classifier**:
  - Concatenates pooled CNN feature (256-d) with scalar embedding (64-d)  
  - Linear(320 â†’ 256) â†’ ReLU â†’ BatchNorm â†’ Dropout  
  - Linear(256 â†’ 128) â†’ ReLU â†’ BatchNorm  
  - Linear(128 â†’ 1) â†’ output logit

- **Total Parameters**: **~2.43M**

 
### ğŸ“¦ VGG-Inspired

Inspired by the VGG family, enhanced with GELU, residual connection, and aggressive regularizations.

- **Input**:  
  - Spectrogram input: `shape = [B, 9, H, W]`  
  - Scalar input: 39-dimensional waveform-derived vector

- **Spectrogram Branch**:
  - **Block 1**: 3 Ã— Conv2D(64) â†’ BatchNorm â†’ GELU â†’ Downsample  
  - **Block 2**: 3 Ã— Conv2D(128) â†’ BatchNorm â†’ GELU â†’ MaxPool  
  - **Block 3**: 3 Ã— Conv2D(256) â†’ BatchNorm â†’ GELU â†’ MaxPool  
  - **Block 4**: 3 Ã— Conv2D(512) â†’ BatchNorm â†’ GELU  
    - **Residual path**: Conv2D(256 â†’ 512) â†’ BatchNorm  
    - Output = Main + Residual  
  - Final: `AdaptiveAvgPool2d((1, 1))`

- **Scalar Branch**:
  - Linear(39 â†’ 64) â†’ BatchNorm â†’ GELU â†’ Dropout  
  - Linear(64 â†’ 64) â†’ BatchNorm â†’ GELU

- **Classifier**:
  - Concatenates pooled CNN feature (512-d) with scalar embedding (64-d)  
  - Linear(576 â†’ 256) â†’ BatchNorm â†’ GELU â†’ Dropout  
  - Linear(256 â†’ 128) â†’ BatchNorm â†’ GELU â†’ Dropout  
  - Linear(128 â†’ 1) â†’ output logit

- **Total Parameters**: **~8.15M**

### ğŸ”— Final Prediction Aggregation

Each model outputs a sigmoid-activated probability. The final prediction is a weighted average:

Let:
- `M = {modelâ‚, modelâ‚‚, ..., modelâ‚™}` be the set of models (here: CNN8 and VGG)
- `logitsáµ¢` be the raw output of model *i*
- `Ïƒ(logitsáµ¢)` be the sigmoid activation (i.e., predicted probability)
- `wáµ¢` be the validation score of model *i*
- `Î±áµ¢ = softmax(wáµ¢)` if `use_softmax_weights = True`, else normalized directly

Then the final ensemble output is:

```math
P_\text{final} = \sum_{i=1}^{n} \alpha_i \cdot \sigma(\text{logits}_i)
```

